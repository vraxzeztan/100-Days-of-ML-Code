{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anusar_Soni - Text_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "q_5_OMK9VsTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import string\n",
        "import pandas as pd\n",
        "import os\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzNtI00DWEhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58813309-a44c-47c7-fbef-0f05cb1f2be1"
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve (\"https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20_newsgroups.tar.gz\", \"a.tar.gz\")\n",
        "urllib.request.urlretrieve (\"http://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz\", \"b.tar.gz\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('b.tar.gz', <http.client.HTTPMessage at 0x7fa2cf4c6048>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "hWRqzyFnXyv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"a.tar.gz\")\n",
        "tar2 = tarfile.open(\"b.tar.gz\")\n",
        "tar.extractall()\n",
        "tar2.extractall()\n",
        "tar.close()\n",
        "tar2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahIvVqsCHVvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "68d5cd07-57eb-495f-8f06-d74099fd0726"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "vVXkLmkObUSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "block_wrds = ['sender:','subject:','writes:','references:','organization:','from:','date:','>i','22','|>','>>','reply-to:','xref:','newsgroups:','>in','>the','message-id:','lines:','path:','re:','--','sender:','last','better','never','every','even','two','good','used','first','need','going','must','really','might','well','without','made','give','look','try','far','less','seem','new','make','many','way','since','using','take','help','thanks','send','free','may','see','much','want','find','would','one','like','get','use','also','could','say','us','go','please','said','set','got','sure','come','lot','seems','able','anything','put']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nz5IledlL3nV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# making the dictionary by finding the frequency of each word in the docs "
      ]
    },
    {
      "metadata": {
        "id": "X2BArPXMHjTq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dictionary = {}\n",
        "count=0\n",
        "for file in os.listdir(\"mini_newsgroups\"): # making the features list by finding the frequency of each word in the docs \n",
        "    for files in os.listdir(\"mini_newsgroups/\"+file):\n",
        "        f = open(\"mini_newsgroups/\"+file+\"/\"+files,'r',errors='ignore')\n",
        "        message = f.read()\n",
        "        message = message.split()\n",
        "        k =1\n",
        "        for i in message:\n",
        "            count +=1\n",
        "            if(len(i) > 1):\n",
        "                if not i.lower() in stop_words:\n",
        "                    if not i.lower() in block_wrds:\n",
        "                        if(i.lower() in dictionary.keys()):\n",
        "                            dictionary[i.lower()] = dictionary[i.lower()] +1\n",
        "                        else:\n",
        "                            dictionary[i.lower()] = 1\n",
        "\n",
        "\n",
        "        f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_8Tpl5-b88u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import operator\n",
        "sorted_vocab = sorted(dictionary.items(), key= operator.itemgetter(1), reverse= True)   # sort the vocab based on frequency\n",
        "#sorted_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "he7cuAKJb_Q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "227c897c-6d45-4750-c71b-59dd5b226505"
      },
      "cell_type": "code",
      "source": [
        "len(sorted_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "zqfGgxe8MCyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## creating feature names or column names by taking top repeating words from dictionary"
      ]
    },
    {
      "metadata": {
        "id": "5HS8Fd-ZIty5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_names = []\n",
        "for i in range(len(sorted_vocab)):\n",
        "    if(sorted_vocab[1000][1] <= sorted_vocab[i][1]):\n",
        "        feature_names.append(sorted_vocab[i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KybIxHYPItvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba314d45-4b40-4973-9759-0e0a8ef6c46d"
      },
      "cell_type": "code",
      "source": [
        "len(feature_names)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "p4quK0SUKGeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GO THROUGH EACH DOCUMENT AND SEE FOR EVERY WORD IF THAT WORD IS A FEATURE NAME OR NOT"
      ]
    },
    {
      "metadata": {
        "id": "UpqVvuQrJ4nA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0621651f-12db-427d-d37d-9bc825b2dd6f"
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=feature_names)\n",
        "count=0\n",
        "for file in os.listdir(\"20_newsgroups\"):\n",
        "    for files in os.listdir(\"20_newsgroups/\"+file):\n",
        "        count=count+1\n",
        "        df.loc[len(df)] = np.zeros(len(feature_names))\n",
        "        f = open(\"20_newsgroups/\"+file+\"/\"+files,'r',errors='ignore')\n",
        "        message = f.read()\n",
        "        message = message.split()\n",
        "        k =0\n",
        "        for i in message:\n",
        "            if(i.lower() in df.columns):\n",
        "                df[i.lower()][len(df)-1] += 1\n",
        "        f.close()\n",
        "count"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "joUsXmF1POys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## store each output class in y"
      ]
    },
    {
      "metadata": {
        "id": "Qz-0SG6xKhAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "101f1c91-4547-4c65-d76e-7a7303f66d61"
      },
      "cell_type": "code",
      "source": [
        "y=[]\n",
        "i=0\n",
        "count=0\n",
        "for file in os.listdir(\"20_newsgroups\"):\n",
        "    for files in os.listdir(\"20_newsgroups/\"+file):\n",
        "        count+=1\n",
        "        y.append(i)\n",
        "    i=i+1\n",
        "    \n",
        "set(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "lyJwaDsePbf4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = df.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRmyFI6ZPhSe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the data for INBUILT MNB CLASSIFIER"
      ]
    },
    {
      "metadata": {
        "id": "7vEgS0jiKgz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Iz8BzdYKgdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbQl80fRfenx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "085f338b-d173-49d5-a0e2-3fc5f1d11c96"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.95      0.97      0.96       228\n",
            "          1       0.84      0.89      0.87       238\n",
            "          2       0.88      0.80      0.83       274\n",
            "          3       0.90      0.83      0.86       260\n",
            "          4       0.79      0.69      0.74       270\n",
            "          5       0.50      0.76      0.60       157\n",
            "          6       0.89      0.71      0.79       326\n",
            "          7       0.96      0.91      0.94       284\n",
            "          8       0.84      0.85      0.85       280\n",
            "          9       0.70      0.87      0.77       199\n",
            "         10       0.42      0.57      0.48       170\n",
            "         11       0.85      0.77      0.81       256\n",
            "         12       0.89      0.84      0.87       260\n",
            "         13       0.88      0.87      0.88       258\n",
            "         14       0.83      0.71      0.76       286\n",
            "         15       0.78      0.92      0.84       216\n",
            "         16       0.83      0.87      0.85       239\n",
            "         17       0.85      0.94      0.89       253\n",
            "         18       0.93      0.82      0.87       295\n",
            "         19       1.00      0.94      0.97       251\n",
            "\n",
            "avg / total       0.84      0.83      0.83      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "laRIahSHQI7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SELF IMPLEMENTED MULTINOMIAL NAIVE BAYES\n"
      ]
    },
    {
      "metadata": {
        "id": "RD4GuijwWxLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['out'] = y\n",
        "Y = df['out']\n",
        "X = df.iloc[:,:-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zxHbJ1o6QSsI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNKaj85vfkUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit(X_train,Y_train):\n",
        "    result = {}\n",
        "    result[\"total_data\"] = len(Y_train)\n",
        "    output_classes = set(Y_train)\n",
        "    for current_class in output_classes:\n",
        "        result[current_class] = {}\n",
        "        \n",
        "        current_class_rows = (Y_train == current_class)\n",
        "        X_train_current = X_train[current_class_rows]\n",
        "        Y_train_current = Y_train[current_class_rows]\n",
        "        \n",
        "        sum = 0\n",
        "        for j in (feature_names):\n",
        "            result[current_class][j] = X_train_current[j].sum()\n",
        "            sum += result[current_class][j]\n",
        "            \n",
        "        result[current_class][\"total_count\"] = sum\n",
        "            \n",
        "    return result        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FKbac3Pxf10a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def probability(dictionary, row, current_class):\n",
        "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
        "    \n",
        "    for index,count in row.iteritems():\n",
        "        \n",
        "        feature_name = index\n",
        "        feature_count = count\n",
        "        \n",
        "        num = dictionary[current_class][feature_name] + 1                          #  LAPLACE CORRECTION\n",
        "        den = dictionary[current_class]['total_count'] + len(feature_names)\n",
        "        \n",
        "        current_word_prob = np.log(num) - np.log(den)\n",
        "        for i in range(int(count)):\n",
        "          output += current_word_prob        \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYlsxRwAgF3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_single_row(dictionary, row):\n",
        "    classes = dictionary.keys()\n",
        "    best_class = -1\n",
        "    best_p = -10\n",
        "    first_run = True\n",
        "    \n",
        "    for current_class in classes:\n",
        "      \n",
        "        if current_class == 'total_data':\n",
        "            continue\n",
        "        p_current_class = probability(dictionary,row,current_class)\n",
        "        if (first_run or p_current_class > best_p):     # comapare each classes and find the best one\n",
        "            best_p = p_current_class\n",
        "            best_class = current_class\n",
        "        first_run = False\n",
        "    return best_class\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LShUToU-gHMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(dictionary,x_test):\n",
        "    Y_pred = []\n",
        "    for j in x_test.iterrows():\n",
        "    \n",
        "        x_class = predict_single_row(dictionary,j[1]) # pass each document (row) to the predict_single_row function\n",
        "        Y_pred.append(x_class)\n",
        "\n",
        "    return Y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBnJ1T1-gIwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dictionary = fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81K77dx-gKgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "767f8d01-3703-4a72-8968-aac5d2ecae13"
      },
      "cell_type": "code",
      "source": [
        "y_pred = predict(dictionary,x_test)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.95      0.98      0.96       226\n",
            "          1       0.85      0.88      0.86       245\n",
            "          2       0.88      0.80      0.84       275\n",
            "          3       0.90      0.83      0.87       260\n",
            "          4       0.81      0.70      0.75       273\n",
            "          5       0.52      0.75      0.61       166\n",
            "          6       0.88      0.75      0.81       308\n",
            "          7       0.96      0.92      0.94       281\n",
            "          8       0.85      0.86      0.85       280\n",
            "          9       0.70      0.86      0.77       201\n",
            "         10       0.42      0.56      0.48       170\n",
            "         11       0.85      0.78      0.81       255\n",
            "         12       0.89      0.85      0.87       257\n",
            "         13       0.88      0.87      0.88       258\n",
            "         14       0.84      0.71      0.77       290\n",
            "         15       0.79      0.91      0.85       219\n",
            "         16       0.85      0.86      0.85       244\n",
            "         17       0.85      0.94      0.89       256\n",
            "         18       0.93      0.85      0.89       284\n",
            "         19       1.00      0.93      0.96       252\n",
            "\n",
            "avg / total       0.84      0.83      0.83      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}